{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/DLI_Header.png\" style=\"width: 400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, you've learned some valuable skills along the way and had fun doing it. Now it's time to put those skills to the test. In this assessment, you will train a new model that is able to recognize fresh and rotten fruit. You will need to get the model to a validation accuracy of `92%` in order to pass the assessment, though we challenge you to do even better if you can. You will have the use the skills that you learned in the previous exercises. Specifically, we suggest using some combination of transfer learning, data augmentation, and fine tuning. Once you have trained the model to be at least 92% accurate on the validation dataset, save your model, and then assess its accuracy. Let's get started! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will train a model to recognize fresh and rotten fruits. The dataset comes from [Kaggle](https://www.kaggle.com/sriramr/fruits-fresh-and-rotten-for-classification), a great place to go if you're interested in starting a project after this class. The dataset structure is in the `data/fruits` folder. There are 6 categories of fruits: fresh apples, fresh oranges, fresh bananas, rotten apples, rotten oranges, and rotten bananas. This will mean that your model will require an output layer of 6 neurons to do the categorization successfully. You'll also need to compile the model with `categorical_crossentropy`, as we have more than two categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fruits.png\" style=\"width: 600px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ImageNet Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We encourage you to start with a model pretrained on ImageNet. Load the model with the correct weights, set an input shape, and choose to remove the last layers of the model. Remember that images have three dimensions: a height, and width, and a number of channels. Because these pictures are in color, there will be three channels for red, green, and blue. We've filled in the input shape for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "base_model = keras.applications.VGG16(\n",
    "    weights= 'imagenet',\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze base model\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Layers to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 14,717,766\n",
      "Trainable params: 3,078\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create inputs with correct shape\n",
    "inputs = keras.Input(shape=(224, 224, 3))  # Adjust the shape as needed\n",
    "\n",
    "# Pass inputs through the base model\n",
    "x = base_model(inputs, training=False)\n",
    "\n",
    "# Add Global Average Pooling Layer\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)  # You can also use GlobalMaxPooling2D\n",
    "\n",
    "# Add final dense layer\n",
    "num_classes = 6  # Set the number of classes (types of fruit) you have\n",
    "outputs = keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Combine inputs and outputs to create the model\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# Print model summary to check the architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to compile the model with loss and metrics options. Remember that we're training on a number of different categories, rather than a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',  # For multi-class classification\n",
    "    optimizer='adam',  # You can choose other optimizers as well\n",
    "    metrics=['accuracy']  # Accuracy is a common metric for classification\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,          # Normalize pixel values to [0, 1]\n",
    "    rotation_range=20,        # Randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.2,    # Randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,   # Randomly shift images vertically (fraction of total height)\n",
    "    shear_range=0.2,          # Shear intensity (shear angle in counter-clockwise direction as radians)\n",
    "    zoom_range=0.2,           # Randomly zoom in/out on images\n",
    "    horizontal_flip=True,     # Randomly flip images horizontally\n",
    "    fill_mode='nearest'       # Fill points outside the input boundaries using the nearest available pixel\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1182 images belonging to 6 classes.\n",
      "Found 329 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# load and iterate training dataset\n",
    "train_it = datagen.flow_from_directory('data/fruits/train',          # Path to the training data directory\n",
    "                                      target_size=(224, 224), \n",
    "                                       color_mode='rgb', \n",
    "                                       class_mode=\"categorical\")\n",
    "# load and iterate validation dataset\n",
    "valid_it = datagen.flow_from_directory('data/fruits/valid',     # Path to the validation data directory\n",
    "    target_size=(224, 224),\n",
    "                                      color_mode='rgb', \n",
    "                                      class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to train the model! Pass the `train` and `valid` iterators into the `fit` function, as well as setting your desired number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "37/36 [==============================] - 29s 781ms/step - loss: 1.7450 - accuracy: 0.2479 - val_loss: 1.6042 - val_accuracy: 0.4012\n",
      "Epoch 2/25\n",
      "37/36 [==============================] - 24s 645ms/step - loss: 1.5379 - accuracy: 0.4509 - val_loss: 1.4527 - val_accuracy: 0.5866\n",
      "Epoch 3/25\n",
      "37/36 [==============================] - 22s 594ms/step - loss: 1.3864 - accuracy: 0.6413 - val_loss: 1.3081 - val_accuracy: 0.6079\n",
      "Epoch 4/25\n",
      "37/36 [==============================] - 22s 590ms/step - loss: 1.2701 - accuracy: 0.6438 - val_loss: 1.2185 - val_accuracy: 0.7234\n",
      "Epoch 5/25\n",
      "37/36 [==============================] - 22s 585ms/step - loss: 1.1687 - accuracy: 0.7310 - val_loss: 1.1165 - val_accuracy: 0.7842\n",
      "Epoch 6/25\n",
      "37/36 [==============================] - 22s 587ms/step - loss: 1.0880 - accuracy: 0.7403 - val_loss: 1.0305 - val_accuracy: 0.7660\n",
      "Epoch 7/25\n",
      "37/36 [==============================] - 21s 577ms/step - loss: 1.0203 - accuracy: 0.7707 - val_loss: 0.9852 - val_accuracy: 0.7416\n",
      "Epoch 8/25\n",
      "37/36 [==============================] - 21s 579ms/step - loss: 0.9669 - accuracy: 0.7479 - val_loss: 0.9419 - val_accuracy: 0.7629\n",
      "Epoch 9/25\n",
      "37/36 [==============================] - 21s 580ms/step - loss: 0.9042 - accuracy: 0.7868 - val_loss: 0.8792 - val_accuracy: 0.8085\n",
      "Epoch 10/25\n",
      "37/36 [==============================] - 21s 581ms/step - loss: 0.8701 - accuracy: 0.8105 - val_loss: 0.8728 - val_accuracy: 0.8055\n",
      "Epoch 11/25\n",
      "37/36 [==============================] - 21s 576ms/step - loss: 0.8323 - accuracy: 0.8274 - val_loss: 0.8075 - val_accuracy: 0.8298\n",
      "Epoch 12/25\n",
      "37/36 [==============================] - 22s 588ms/step - loss: 0.7967 - accuracy: 0.8130 - val_loss: 0.7867 - val_accuracy: 0.8450\n",
      "Epoch 13/25\n",
      "37/36 [==============================] - 22s 591ms/step - loss: 0.7693 - accuracy: 0.8325 - val_loss: 0.7612 - val_accuracy: 0.8237\n",
      "Epoch 14/25\n",
      "37/36 [==============================] - 22s 587ms/step - loss: 0.7348 - accuracy: 0.8367 - val_loss: 0.7370 - val_accuracy: 0.8419\n",
      "Epoch 15/25\n",
      "37/36 [==============================] - 22s 594ms/step - loss: 0.7143 - accuracy: 0.8308 - val_loss: 0.7038 - val_accuracy: 0.8359\n",
      "Epoch 16/25\n",
      "37/36 [==============================] - 22s 589ms/step - loss: 0.6903 - accuracy: 0.8333 - val_loss: 0.7198 - val_accuracy: 0.8389\n",
      "Epoch 17/25\n",
      "37/36 [==============================] - 22s 588ms/step - loss: 0.6648 - accuracy: 0.8486 - val_loss: 0.6977 - val_accuracy: 0.8085\n",
      "Epoch 18/25\n",
      "37/36 [==============================] - 22s 585ms/step - loss: 0.6465 - accuracy: 0.8528 - val_loss: 0.6708 - val_accuracy: 0.8237\n",
      "Epoch 19/25\n",
      "37/36 [==============================] - 22s 594ms/step - loss: 0.6379 - accuracy: 0.8486 - val_loss: 0.6315 - val_accuracy: 0.8663\n",
      "Epoch 20/25\n",
      "37/36 [==============================] - 22s 584ms/step - loss: 0.6144 - accuracy: 0.8596 - val_loss: 0.6203 - val_accuracy: 0.8632\n",
      "Epoch 21/25\n",
      "37/36 [==============================] - 22s 586ms/step - loss: 0.6161 - accuracy: 0.8418 - val_loss: 0.6265 - val_accuracy: 0.8298\n",
      "Epoch 22/25\n",
      "37/36 [==============================] - 21s 578ms/step - loss: 0.5817 - accuracy: 0.8553 - val_loss: 0.5999 - val_accuracy: 0.8359\n",
      "Epoch 23/25\n",
      "37/36 [==============================] - 22s 588ms/step - loss: 0.5765 - accuracy: 0.8706 - val_loss: 0.5961 - val_accuracy: 0.8663\n",
      "Epoch 24/25\n",
      "37/36 [==============================] - 22s 587ms/step - loss: 0.5555 - accuracy: 0.8655 - val_loss: 0.5997 - val_accuracy: 0.8571\n",
      "Epoch 25/25\n",
      "37/36 [==============================] - 22s 590ms/step - loss: 0.5498 - accuracy: 0.8714 - val_loss: 0.5761 - val_accuracy: 0.8328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8030039358>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_it,\n",
    "          validation_data=valid_it,\n",
    "          steps_per_epoch=train_it.samples/train_it.batch_size,\n",
    "          validation_steps=valid_it.samples/valid_it.batch_size,\n",
    "          epochs= 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfreeze Model for Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the base model\n",
    "base_model.trainable = True  # Set to 'True' to unfreeze the layers\n",
    "\n",
    "# Compile the model with a low learning rate\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-5),  # Adjust the learning rate as needed\n",
    "    loss='categorical_crossentropy',  # For multi-class classification\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "37/36 [==============================] - 33s 889ms/step - loss: 0.3584 - accuracy: 0.8782 - val_loss: 0.2816 - val_accuracy: 0.8967\n",
      "Epoch 2/10\n",
      "37/36 [==============================] - 24s 660ms/step - loss: 0.2032 - accuracy: 0.9264 - val_loss: 0.1651 - val_accuracy: 0.9331\n",
      "Epoch 3/10\n",
      "37/36 [==============================] - 23s 624ms/step - loss: 0.1398 - accuracy: 0.9442 - val_loss: 0.1572 - val_accuracy: 0.9453\n",
      "Epoch 4/10\n",
      "37/36 [==============================] - 23s 610ms/step - loss: 0.1079 - accuracy: 0.9560 - val_loss: 0.1935 - val_accuracy: 0.9392\n",
      "Epoch 5/10\n",
      "37/36 [==============================] - 22s 599ms/step - loss: 0.0957 - accuracy: 0.9611 - val_loss: 0.1392 - val_accuracy: 0.9483\n",
      "Epoch 6/10\n",
      "37/36 [==============================] - 23s 620ms/step - loss: 0.0735 - accuracy: 0.9704 - val_loss: 0.0811 - val_accuracy: 0.9787\n",
      "Epoch 7/10\n",
      "37/36 [==============================] - 23s 623ms/step - loss: 0.0645 - accuracy: 0.9788 - val_loss: 0.0762 - val_accuracy: 0.9696\n",
      "Epoch 8/10\n",
      "37/36 [==============================] - 22s 605ms/step - loss: 0.0510 - accuracy: 0.9848 - val_loss: 0.1222 - val_accuracy: 0.9605\n",
      "Epoch 9/10\n",
      "37/36 [==============================] - 23s 618ms/step - loss: 0.0404 - accuracy: 0.9839 - val_loss: 0.0977 - val_accuracy: 0.9453\n",
      "Epoch 10/10\n",
      "37/36 [==============================] - 23s 618ms/step - loss: 0.0284 - accuracy: 0.9915 - val_loss: 0.0767 - val_accuracy: 0.9787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8046308b38>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_it,\n",
    "          validation_data=valid_it,\n",
    "          steps_per_epoch=train_it.samples/train_it.batch_size,\n",
    "          validation_steps=valid_it.samples/valid_it.batch_size,\n",
    "          epochs= 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a model that has a validation accuracy of 92% or higher. If not, you may want to go back and either run more epochs of training, or adjust your data augmentation. \n",
    "\n",
    "Once you are satisfied with the validation accuracy, evaluate the model by executing the following cell. The evaluate function will return a tuple, where the first value is your loss, and the second value is your accuracy. To pass, the model will need have an accuracy value of `92% or higher`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/10 [================================] - 4s 377ms/step - loss: 0.0713 - accuracy: 0.9787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07129742205142975, 0.978723406791687]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(valid_it, steps=valid_it.samples/valid_it.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess your model run the following two cells.\n",
    "\n",
    "**NOTE:** `run_assessment` assumes your model is named `model` and your validation data iterator is called `valid_it`. If for any reason you have modified these variable names, please update the names of the arguments passed to `run_assessment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_assessment import run_assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model 5 times to obtain average accuracy...\n",
      "\n",
      "11/10 [================================] - 4s 376ms/step - loss: 0.0836 - accuracy: 0.9726\n",
      "11/10 [================================] - 4s 388ms/step - loss: 0.0749 - accuracy: 0.9818\n",
      "11/10 [================================] - 4s 383ms/step - loss: 0.0985 - accuracy: 0.9696\n",
      "11/10 [================================] - 4s 382ms/step - loss: 0.1151 - accuracy: 0.9696\n",
      "11/10 [================================] - 4s 382ms/step - loss: 0.0468 - accuracy: 0.9757\n",
      "\n",
      "Accuracy required to pass the assessment is 0.92 or greater.\n",
      "Your average accuracy is 0.9739.\n",
      "\n",
      "Congratulations! You passed the assessment!\n",
      "See instructions below to generate a certificate.\n"
     ]
    }
   ],
   "source": [
    "run_assessment(model, valid_it)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
